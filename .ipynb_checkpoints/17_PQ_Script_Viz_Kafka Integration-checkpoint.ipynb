{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0b8975",
   "metadata": {},
   "source": [
    "## PQ <-> Kafka Integration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e31088",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONNECT YOUR KAFKA STREAM TO YOUR PYTHON SCRIPT\n",
    "# Start with creating a client for kafka port\n",
    "from ksql import KSQLAPI\n",
    "client = KSQLAPI('http://localhost:8088')\n",
    "\n",
    "# You can also print the description of your schema \n",
    "client.ksql('describe i4Q_DataStream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e407f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By creating a query from your Kafka Stream, you can directly print current streamed messages\n",
    "query = client.query('SELECT * from I4Q_DATASTREAM EMIT CHANGES;')\n",
    "\n",
    "#for item in query:\n",
    "#    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE FUNCTION FOR AN INITIAL DATA FRAME, CONSISTING OF LATEST STREAM MESSAGES\n",
    "# This function takes the former printed streams and stores them in panda data frames\n",
    "# create_df_from_kafka() creates a pandas dataframe of the last n records\n",
    "# read_latest_message() creates a single row in pandas data frame format of the last streamed message\n",
    "\n",
    "\n",
    "from ksql import KSQLAPI\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import schedule\n",
    "import time\n",
    "from itertools import count\n",
    "\n",
    "def create_df_from_kafka():\n",
    "\n",
    "    # insert your ksql query here with latest updated message\n",
    "    query = client.query('SELECT * from I4Q_DATASTREAM EMIT CHANGES LIMIT 5;')\n",
    "\n",
    "    # take all as string and avoid runtime error\n",
    "    whole = ''\n",
    "    try:\n",
    "        for item in query: \n",
    "            whole += item\n",
    "    except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    # adjust json file \n",
    "    records = json.loads(whole.strip().replace('\\n\\n\\n\\n', ''))\n",
    "\n",
    "    # take header as string with separate column names\n",
    "    header = str(np.array(records[0]).tolist()).split('`')\n",
    "\n",
    "    # hard code columns to delete which are not applicable to the df\n",
    "    header_subset = ['query', 'schema', 'BIGINT', ' STRING', 'DOUBLE']\n",
    "\n",
    "    # delete inconvenient column names\n",
    "    esc_lst = [re.escape(header_subset) for header_subset in header]\n",
    "\n",
    "    # delete split character '\\\\'\n",
    "    cols = [ x for x in esc_lst if \"\\\\\" not in x ]\n",
    "\n",
    "    # address 2D data without header and last row (which is always the exit from the limited query)\n",
    "    data = [r['row']['columns'] for r in records[1:-1]]\n",
    "    \n",
    "    # create convenient data frame\n",
    "    df = pd.DataFrame(data=data, columns=cols)\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "def read_latest_message():\n",
    "    # insert your ksql query here with latest updated message\n",
    "    query = client.query('SELECT * from I4Q_DATASTREAM EMIT CHANGES LIMIT 1;')\n",
    "\n",
    "    # take all as string and avoid runtime error\n",
    "    whole = ''\n",
    "    try:\n",
    "        for item in query: \n",
    "            whole += item\n",
    "    except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    # adjust json file \n",
    "    records = json.loads(whole.strip().replace('\\n\\n\\n\\n', ''))\n",
    "\n",
    "    # take header as string with separate column names\n",
    "    header = str(np.array(records[0]).tolist()).split('`')\n",
    "\n",
    "    # hard code columns to delete which are not applicable to the df\n",
    "    header_subset = ['query', 'schema', 'BIGINT', ' STRING', 'DOUBLE']\n",
    "\n",
    "    # delete inconvenient column names\n",
    "    esc_lst = [re.escape(header_subset) for header_subset in header]\n",
    "\n",
    "    # delete split character '\\\\'\n",
    "    cols = [ x for x in esc_lst if \"\\\\\" not in x ]\n",
    "\n",
    "    # address 2D data without header and last row (which is always the exit from the limited query)\n",
    "    data = [r['row']['columns'] for r in records[1:-1]]\n",
    "\n",
    "    # convert to appropriate data type\n",
    "    new_row = pd.DataFrame(data=data, columns=cols)\n",
    "    \n",
    "    return new_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d59c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE DATA FRAME WHICH IS CONTINUOUSLY UPDATED BY EACH NEW MESSAGE\n",
    "\n",
    "def update_df():\n",
    "    # start with already existing or with empty data frame\n",
    "    df = pd.concat([create_df_from_kafka(), read_latest_message()])\n",
    "    \n",
    "    # if you want, you can delete the oldest message by keeping everything except the first row\n",
    "    # df = df.iloc[1: , :]\n",
    "    \n",
    "    # loop it together to continuously add messages\n",
    "    for i in range(len(df)):\n",
    "        df = pd.concat([df, read_latest_message()])\n",
    "        # df = df.iloc[1: , :]\n",
    "   \n",
    "    return df\n",
    "\n",
    "df = update_df()\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd484b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CREATE FUNCTIONS TO PLOT LAST UPDATED KAFKA MESSAGE\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# By creating a class with initial and depending processing, we can easily implement this plot later\n",
    "class LivePlotNotebook(object):\n",
    "\n",
    "    # First create the initial plot itself\n",
    "    def __init__(self):\n",
    "        %matplotlib notebook\n",
    "        \n",
    "        # create empty plot of the frame of the XLINE chart (default size can be adjusted)\n",
    "        fig, ax = plt.subplots(figsize = (9,4))\n",
    "        \n",
    "        # create line plot for dependent variable which has to be visualized (20 is the default for the plotted values)\n",
    "        ax.plot([0]*20, label='response', color='#595959')\n",
    "        \n",
    "        # set limits for axis\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        # create legend with default tick numbering and name it \"values\"\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('values')\n",
    "        \n",
    "        # create grid background for better reading\n",
    "        ax.grid()\n",
    "                \n",
    "        # calculate Process Mean\n",
    "        process_mean = df['RESPONSE'].mean()\n",
    "        \n",
    "        # create the Upper Control Limit Line\n",
    "        UCL = 0.75\n",
    "        line2 = ax.axhline(UCL, color='#8B569C')\n",
    "        \n",
    "        # create the Lower Control Limit Line\n",
    "        LCL = 0.3\n",
    "        line3 = ax.axhline(LCL, color='#8B569C')\n",
    "        \n",
    "         # Create mean line\n",
    "        line4 = ax.axhline(process_mean, color='#EAD6FF')\n",
    "        \n",
    "        # address and overwrite plot variables for convenient processing\n",
    "        self.ax = ax\n",
    "        self.fig = fig\n",
    "       \n",
    "        # Create a chart title\n",
    "        ax.set_title('Process Control Chart', color='#8064a2')\n",
    "\n",
    "        # determine the x-axis limits in the chart to attach reference values\n",
    "        left, right = self.ax.get_xlim()\n",
    "        \n",
    "        # create formatted values to display in the plot\n",
    "        ax.text(20.2,UCL, \"UCL = \" + str(\"{:.2f}\".format(UCL)), color='#8B569C')\n",
    "        ax.text(20.2, process_mean, r'$\\bar{x}$' + \" = \" + str(\"{:.2f}\".format(process_mean)), color='#EAD6FF')\n",
    "        ax.text(20.2, LCL, \"LCL = \" + str(\"{:.2f}\".format(LCL)), color='#8B569C')\n",
    "        \n",
    "    # Now, take the plot and let run continuous updates\n",
    "    def update(self, x, actions):             \n",
    "        \n",
    "        # update by taking the first object\n",
    "        line = self.ax.lines[0]\n",
    "        \n",
    "        # take lenghth of data for convenient visualization\n",
    "        line.set_xdata(range(len(x)))\n",
    "        line.set_ydata(x)\n",
    "        \n",
    "        # update action plots\n",
    "        for i, line in enumerate(self.ax.lines[1:]):\n",
    "            # iterate over dataframe to take x and y values\n",
    "            line.set_xdata(np.argwhere(actions==i).T)               \n",
    "            line.set_ydata(x[actions==i])\n",
    "\n",
    "            # update limits to let \n",
    "            self.ax.set_xlim(0, len(actions)+5)\n",
    "            self.ax.set_ylim(0, 1)\n",
    "\n",
    "            # visualize again\n",
    "            self.fig.canvas.draw()\n",
    "            \n",
    "            return actions\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can finally create our continuously updated plot \n",
    "\n",
    "import time\n",
    "\n",
    "# call former defined class\n",
    "liveplot = LivePlotNotebook()\n",
    "\n",
    "# determine columns of interest which has to be visualized\n",
    "response = df['RESPONSE']\n",
    "\n",
    "# process data for appropriate plot integration and define number of \"actions\" which is the number of visualized data points \n",
    "x = response[:1]\n",
    "actions = [0]*16\n",
    "\n",
    "# create loop which iterates over length of addressed data \n",
    "for i in range(1,response.count()):\n",
    "    \n",
    "    # set time between updates in seconds\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # append the latest row to the empty array\n",
    "    act=np.append(actions[1:15],response[i])\n",
    "\n",
    "    # call function for plot update with defined number of actions\n",
    "    actions = liveplot.update(\n",
    "        x=act,\n",
    "        actions=act\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77d70b",
   "metadata": {},
   "source": [
    "HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "# Enable interactive plot\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "# Fixing bin edges\n",
    "HIST_BINS = np.linspace(0.2, 2, 100)\n",
    "\n",
    "# histogram our data from dataframe\n",
    "data = response\n",
    "n, _ = np.histogram(data, HIST_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_animation(bar_container):\n",
    "    \n",
    "    def animate(frame_number):\n",
    "        # simulate new data coming in\n",
    "        data = np.array([response[:frame_number]])\n",
    "        n, _ = np.histogram(data, HIST_BINS)\n",
    "        #Loop to update the height of the bins for each new data coming in \n",
    "        for count, rect in zip(n, bar_container.patches):\n",
    "            rect.set_height(count)\n",
    "        return bar_container.patches\n",
    "    \n",
    "    return animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07eeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw Histogram and define the figure size \n",
    "fig, ax = plt.subplots(figsize = (9,9))\n",
    "_, _, bar_container = ax.hist(data, HIST_BINS, lw=1,\n",
    "                              ec=\"#8B569C\", fc=\"purple\", alpha=0.5)\n",
    "ax.set_ylim(top=227)  # set safe limit to ensure that all data is visible.\n",
    "\n",
    "#ax = df.hist(column='response', bins=27, grid=False, figsize=(8,7), color='purple', zorder=2, rwidth=0.8)\n",
    "\n",
    "\n",
    "# Despine\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "# Switch off ticks\n",
    "ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\", labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "# Draw horizontal axis lines\n",
    "vals = ax.get_yticks()\n",
    "for tick in vals:\n",
    "    ax.axhline(y=tick, linestyle='dashed', alpha=0.4, color='#eeeeee', zorder=1)\n",
    "\n",
    "# Set title\n",
    "ax.set_title(\"Histogram for Process Control\")\n",
    "\n",
    "# Set x-axis label\n",
    "ax.set_xlabel(\"Sensor Response\", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel(\" Counter \", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "# Format y-axis label\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,g}'))\n",
    "\n",
    "\n",
    "# Create the Upper Control Limit Line\n",
    "UCL = 0.8\n",
    "line2 = ax.axvline(UCL, color='#8B569C', linestyle = '--', label ='UCL')\n",
    "\n",
    "# Create the Lower Control Limit Line\n",
    "LCL = 0.3\n",
    "line3 = ax.axvline(LCL, color='#8B569C', linestyle = 'dashdot', label = 'LCL')\n",
    "\n",
    "#Show Legend for the Lines (UCL AND LCL)\n",
    "plt.legend()\n",
    "\n",
    "#print(df.size)\n",
    "\n",
    "#Create Continous Histogram \n",
    "ani = animation.FuncAnimation(fig, prepare_animation(bar_container), df.size,\n",
    "                              repeat=False, blit=True)\n",
    "\n",
    "#Plot the Graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def deploy_model():\n",
    "\n",
    "    # read latest message with former created function\n",
    "    last_message = read_latest_message()\n",
    "\n",
    "    # convert latest message to array and slice to read only sensor data\n",
    "    features = np.array(last_message)\n",
    "    features = features[:, 6:12]\n",
    "\n",
    "    # load pre-developed model\n",
    "    rf_model = joblib.load('rf_model.pkl')\n",
    "    \n",
    "    # let model run over latest features \n",
    "    output = rf_model.predict(features)\n",
    "    \n",
    "    print(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "schedule.every(1).seconds.do(deploy_model)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d5dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
